<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <title>Group Meeting Yang Zhang</title>
  <script type="module">
    // Load the three.js for 3d object visualization
    import * as THREE from  "https://cdn.jsdelivr.net/npm/three@0.127.0/build/three.module.js";
    import { OrbitControls } from "https://cdn.jsdelivr.net/npm/three@0.127.0/examples/jsm/controls/OrbitControls.js";
    import { PLYLoader } from "https://cdn.jsdelivr.net/npm/three@0.127.0/examples/jsm/loaders/PLYLoader.js";
    window.THREE = THREE;
    window.OrbitControls = OrbitControls;
    window.PLYLoader = PLYLoader;
  </script>

  <!-- Load reveal.js -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/reveal.min.css" integrity="sha512-V5fKCVKOFy36w8zJmLzPH5R6zU6KvuHOvxfMRczx2ZeqTjKRGSBO9yiZjCKEJS3n6EmENwrH/xvSwXqxje+VVA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/js/reveal.min.js" integrity="sha512-QYXU3Cojl94ZRiZRjUZpyg1odj9mKTON9MsTMzGNx/L3JqvMA3BQNraZwsZ83UeisO+QMVfFa83SyuYYJzR9hw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <!-- Load jQuery-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.9.1/jquery.min.js" integrity="sha512-jGR1T3dQerLCSm/IGEGbndPwzszJBlKQ5Br9vuB0Pw2iyxOy+7AK+lJcCC8eaXyz/9du+bkCy4HXxByhxkHf+w==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <!-- Load 3DMol.js -->
  <script src="https://3Dmol.org/build/3Dmol-min.js"></script>
  <script src="https://3Dmol.org/build/3Dmol.ui-min.js"></script>

  <!-- Load MathJax for labex representation -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS_HTML"></script>

  <!-- Load the customized style sheets -->
  <link rel="stylesheet" type="text/css" href="https://miemiemmmm.b-cdn.net/GM_Feb2024/styles.css">

  <!-- TODO: Comment the following lines for local development. -->
  <!-- <link rel="stylesheet" type="text/css" href="./styles.css"> -->

</head>


<body>
<div class="reveal">
  <!-- Add laser pointer object -->
  <div class="laser-pointer"></div>

  <!-- Welcome page: Set title, seminar info and background image (handled in JavaScript part) -->
  <div class="slides" id="slide_container">
    <section data-state="slide_TitlePage">
      <div style="position:relative; height:40%; width:100%; top:10%">
        <p class="presentation_title" style="color:#1C226B; -webkit-text-stroke: 1.5px blue;">Benchmarking 3D Shape-Based Recognition for Flexible Building Blocks</p>
      </div>

      <p class="presentation_info">Yang Zhang</p>
      <p class="presentation_info">Caflisch Group</p>
      <p class="presentation_info">21st Feb 2024</p>
      <p class="presentation_info">Department of Biochemistry</p>
      <img id="welcome_bgimage" class="bgimg_style_welcome">
    </section>

    <!-- 
      Title and abstract
      Benchmarking 3D Shape-Based Recognition for Flexible Building Blocks
      Atoms are in constant motion, and all but the simplest molecules are flexible, thus being justly called deformable or soft objects. With the eventual goal of deciphering the 3D motion of molecules using machine learning (ML), a fundamental problem arises beforehand: how efficiently can a data-driven model abstract the shape heterogeneity of flexible molecular building blocks, which is manifest also in structural databases like the PDB, while correctly recognizing their identities? This core task will inevitably remain a fundamental component of deployed models, much like basic object recognition and tracking are basic components of the automated mining of video data. In molecules, the design of features is a critical step for many tasks from protein design to drug discovery. Naturally, features must carry task-specific information, yet the methods used for composing them and the role of molecular geometry (shape) in these processes are rarely defined explicitly. In this work, we establish a standard workflow to compare different combinations of standard ML models with various molecular representations. We created a benchmark dataset containing substantial heterogeneity for a given label to offer a platform for rigorous performance comparisons. Our findings reveal that, while it is feasible to train general-purpose models, their efficiency and performance ceiling can differ. We also demonstrate that pretrained models are capable of acquiring transferable knowledge by deploying them to data taken from dynamic trajectories.

      Since atoms are in constant motion, the majority of molecules, except those in simplest forms, are flexible and could be called deformable or soft objects. With the eventual goal of deciphering the 3D motion of molecules using machine learning (ML), I am exploring the possibility of using principles in computer vision (CV) and computer graphics (CG) to process 3D molecular deformation. As direct 3D-based learning is gaining more attention, the choice of representation profoundly impacts model performance. However, before diving into feature engineering, a fundamental question arises: how much structural information does the 3D geometry hold, and how can we effectively capture the inherent shape diversity of these flexible building blocks using data-driven approaches? In tomorrow's group meeting, I will introduce a proof-of-concept study that evaluates various combinations of standard ML models alongside different molecular representations, which aims to assess their ability to capture the dynamic movements of molecules, and correctly recognise their identities. 
     -->
    
    
    <!-- ######################################################### -->
    <section data-state="slide_OutlinePage">
      <p class="slide-title">Outline</p>
      <div class="box_style_mainbody">
        <p class="slide_item_style1" style="font-size: 30px !important; ">1: Introduction </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">2: Three dimensional molecular representations </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">3: Benchmarking the 3D shape perception  </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">4: Three dimensional dynamic feature and potential application </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">5: Future work </p>
      </div>

      <div class="image-style1">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/welcome.png" class="bgimg_style_rbig">
      </div>
    </section>


    <!-- ######################################################### -->
    <section>
			<div class="chapter_break_container">
				<p class="chapter_title">Introduction</p>
				<img>
			</div>
		</section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Overall workflow </p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1 highlight_style1">Ultimate goal: Carry transfereable knowledge from MD trajectories to the downstream tasks </p>
        <p class="slide_item_style1">1. Needs to measure the capacity of the dynamic features (in simplified models)</p>
        <p class="slide_item_style1 highlight_style1" style="font-size: 20px !important;">Encoporate dynamicism in molecular applications </p>
        <p class="slide_item_style1">2. Needs an efficient method to extract the dynamic features from MD trajectories (Part 1,2 in Fig 1) </p> 
        <p class="slide_item_style1 highlight_style1" style="font-size: 20px !important;">Limited complexity</p>
        <p class="slide_item_style1">3. Needs an efficient way to generate the dynamic features from scratch (Part 3 in Fig 1 shows a data-driven manner) </p>
        <p class="slide_item_style1 highlight_style1" style="font-size: 20px !important;">Skip the running of MD simulation</p>

      </div>
      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Overall_workflow.png" style="width: 95% !important; ">
        <p class="content_subtitle">Fig 1. Overall workflow for the information flow of the dynamic features</p>
      </div>
    </section>
    

    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Current dynamic contents in CV/CG</p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1">Human pose recognition </p>
        <p class="slide_item_style1">Human pose generation </p>
        <p class="slide_item_style1">Motion prediction in 3D scene</p>
        <p class="slide_item_style1">Self-driving car </p>
        <p class="slide_item_style1">Robot path planning </p>
        <p class="slide_item_style1" style="font-weight: bold;">\(\cdot \cdot \cdot\)</p>
      </div>

      <div class="box_style_rightbound">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Human_motion.png" style="width: 90% !important; ">
        <div class="caption_container">
          <p class="content_subtitle" style="width: 90% !important;">Fig 1. Human motion generation from textual descriptions </p>
        </div>
        
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Scheme_motion_prediction.png" style="width: 90% !important; ">
        <div class="caption_container">
          <p class="content_subtitle" style="width: 90% !important;">Fig 2. Motion prediction via relative pose encoding </p>
        </div>
      </div>

      <p class="reference_style">
        Petrovich, M., Black, M. J., & Varol, G. (2022). arXiv. https://doi.org/10.48550/ARXIV.2204.14109<br>
        Z. Zhang, A. Liniger, C. Sakaridis, F. Yu, and L. Van Gool, arXiv, 2023. doi: 10.48550/ARXIV.2310.12970.
      </p>
    </section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Commonly used 3D representations</p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1">1. Point cloud (Fig 1, unordered set of points) </p> 
        <p class="slide_item_style1">2. Triangle mesh (characterize surface) </p> 
        <p class="slide_item_style1">3. 3D Voxel (Fig 2, volumetric occupancy) </p> 
        <p class="slide_item_style1">4. Depth map (Fig 3, 2D image encoding 3D infomation by color or intensity of color) </p>
        <p class="slide_item_style1">5. Space-filling curve (encode local proximity via index) </p>
      </div>

      <div class="box_style_llc" style="text-align: center !important; ">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Depthmap_demonstration.png" style="width: 55% !important; "> <br>
        <div style="display: flex !important;" >
          <p class="content_subtitle" style="width: 55% !important; ">Fig 3. Depth map representation of 3D scenes via 2D images. </p>
        </div>
      </div>

      <div class="box_style_fullrightbound">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/PointNet_pointcloud.png" style="width: 80% !important; ">
        <div class="caption_container">
          <p class="content_subtitle" style="width: 80% !important; " >Fig 1. Semantic segmentation of ModelNet objects via PointNet. </p>
        </div>
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/VoxNet_Architecture.png" style="height: 45% !important; ">
        <div class="caption_container">
          <p class="content_subtitle" style="width: 80% !important; ">Fig 2. VoxNet architecture for 3D object recognition. </p>
        </div>
      </div>

      <p class="reference_style">
        C. R. Qi, H. Su, K. Mo, and L. J. Guibas, arXiv, 2016. doi: 10.48550/ARXIV.1612.00593.<br>
        V. Patil, C. Sakaridis, A. Liniger, and L. Van Gool, arXiv, 2022. doi: 10.48550/ARXIV.2204.02091.
      </p>

    </section> 


    <!-- ######################################################### -->
    <section>
			<div class="chapter_break_container">
				<p class="chapter_title">Three dimensional molecular representations</p>
				<img>
			</div>
		</section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Diverse 3D molecular representation</p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1">1. Molecular coordinate is point cloud but typically requires a specific order for topology match </p>
        <!-- <p class="slide_item_style1">2. Molecular coordinates  </p> -->
        <p class="slide_item_style1">2. Surface mesh could be generated by marching cubes algorithm (Fig 1) </p>
        <p class="slide_item_style1">3. 3D voxel compuated by distance-based gaussian mapping (Fig 2) </p>
        <p class="slide_item_style1">4. 3D voxelization requires iteration over each coordinates (requires normalization and summation)</p>
        <p class="slide_item_style1">5. 3D voxel could be mapped to 2D image via space-filling curve (hilbert curve index)</p>

      </div>

      <div class="box_style_rightbound">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/MarchingCubesScheme.png" style="width: 80% !important; ">
        <p class="content_subtitle" style="display: flex !important; width:80% !important" >Fig 1. Schematic representation of marching cubes algorithm for surface generation. </p>
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/gaussian_mapping.png" style="width: 80% !important; ">
        <p class="content_subtitle" style="display: flex !important; width:80% !important" >Fig 2. Distance-based gaussian mapping from one coordinate to grid points. </p>
      </div>

      <p class="reference_style">
        B. Y. Chen, PLoS Computational Biology, vol. 10, no. 8. Public Library of Science (PLoS), p. e1003792, Aug. 28, 2014. doi: 10.1371/journal.pcbi.1003792.<br>
        N. Renaud et al., Nature Communications, vol. 12, no. 1. Springer Science and Business Media LLC, Dec. 03, 2021. doi: 10.1038/s41467-021-27396-0.
      </p>
    </section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">FEater dataset</p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1">FEater (<a style="font-weight: bold;">F</a>lexibility and <a style="font-weight: bold;">E</a>lasticity <a style="font-weight: bold;">A</a>ssessment 
          <a style="font-weight: bold;">T</a>ool for <a style="font-weight: bold;">E</a>ssential <a style="font-weight: bold;">R</a>esidues) can be abbreviated in multiple ways
        </p>

        <p class="slide_item_style1 highlight_style1">Need a platform to measure the invariance of a model to flexible molecular blocks </p>
        <p class="slide_item_style1">1. Contains two datasets FEater-Single and FEater-Dual (Each contains over 8 million structures)</p>
        <p class="slide_item_style1">2. FEater-Single has 20 tags and FEater-Dual has 400 tags (Combination of 20 amino acids)</p>
        <p class="slide_item_style1">3. Source of PDB structures are from PDBBind dataset </p>
        <p class="slide_item_style1">4. Used Hierarchical Data Format (HDF) for dataset storage </p>
      </div> 
        
      <div class="box_style_rightbound" >
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/FEater_Standard_workflow.png" style="width: 90% !important; ">
        <div class="caption_container">
          <p class="content_subtitle" style="width: 90% !important; ">Fig 1. Two-step usage of FEater dataset for benchmarking capacity of the model to classify flexible molecular blocks. </p>
        </div>
        
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/FEater_draftlogo.png" style="height: 50% !important; ">
        <div class="caption_container">
          <p class="content_subtitle" style="width: 90% !important;">Fig 2. Drafted logo for FEater, a voxelized panda eating Phenylalanin (Of course AI failed to draw Phenylalanin correctly); Designed by DALL\(\cdot\)E-3 </p>
        </div>
        
      </div>
    </section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">FEater-Single and FEater-Dual dataset</p>
      <div class="box_style_leftbound">
        <figure class="gallery-item">
          <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/DataDriven_aligned3DMols.png" style="height: 300px; ">
          <figcaption class="content_subtitle" style="width: 80% !important">Fig 1. 100 aligned structures (by \(C_{\alpha}, N, C\)) from FEater-Single dataset </figcaption>
        </figure>
        
      </div>

      <div class="box_style_rightbound gallery-item2" style="text-align: center !important;">
        <figure class="gallery-item">
          <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/DataDrivenVisualization.png" style="height: 300px; ">
          <figcaption class="content_subtitle" style="width: 80% !important">Fig 2. Five example structures from FEater-Single and FEater-Dual datasets (No alignment) </figcaption>
        </figure>
        
      </div>
    </section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Constructure and Featurization of the datasets</p>
      <div class="box_style_leftbound " style="text-align: center !important;"> 
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Algorithm_extraction.png" style="height: 80% !important; ">
        <p class="content_subtitle" style="width: 80% !important;">Fig 1. The algorithm for the extraction of the FEater datasets </p>
      </div>
      <div class="box_style_rightbound">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Algorithm_featurization.png" style="height: 80% !important; ">
        <p class="content_subtitle" style="width: 80% !important;">Fig 2. The algorithm for the featurization of the FEater datasets </p>
      </div>
    </section>


    <!-- ######################################################### -->
    <section>
			<div class="chapter_break_container">
				<p class="chapter_title">Benchmarking the 3D shape perception</p>
				<img>
			</div>
		</section>

    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Various molecular representations VS general-purposed networks </p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1 highlight_style1">Mainly focus on 3D geometries of molecule and involve as least topology as possible </p>
        <p class="slide_item_style1">1. Coordinates could be viewed as point cloud and processed by <a style="font-weight: bold;">PointNet</a> (<a class="highlight_style1">No atom type/bond</a>)</p>
        <p class="slide_item_style1">2. Surface mesh vertices could be viewed as point cloud (<a style="font-weight: bold;">PointNet</a>, <a class="highlight_style1">atomic radii is encoded while surface generation</a>)</p>
        <p class="slide_item_style1">3. Property density map could be viewed as 3D voxel (<a style="font-weight: bold;">VoxNet</a>, <a class="highlight_style1">uniformed atom type</a>)</p>
        <p class="slide_item_style1">4. Transforming 3D voxel to 2D image via hilbert curve (<a style="font-weight: bold;">ResNet</a>)</p>
      </div>

      <div class="box_style_rightbound">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/FEater_Toc.png" style="z-index: -1; width:65% !important" >
      </div>
    </section>


    <!-- ######################################################### -->
    <section data-state="Example_3Dstage_Coord">
      <p class="slide-title">Small quiz: visual inspection (Coordinates) </p>
      <!-- Stage 1 -->
      <div class="box_style_leftbound" style="height: 80% !important; width: 50% !important;">
        <div id="coord_1"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1 " style="font-size: 20px !important; padding-left: 0 !important;">Stage 1: Coordinates feature of <a class="onhover_show" style="border: solid black;">Ile</a></p>
        <div id="coord_3"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1" style="font-size: 20px !important; padding-left: 0 !important;">Stage 2: Coordinates feature of <a class="onhover_show" style="border: solid black;">Cys-Tyr</a></p>
      </div>
      
      
      <!-- Stage 2 -->
      <div class="box_style_rightbound" style="height: 80% !important; width: 50% !important;">
        <div id="coord_2" style="height: 40% !important; width: 90% !important"> </div>
        <p class="slide_item_style1" style="padding-left: 0 !important; font-size: 20px !important; text-align: left !important;">Stage 2: Coordinates of <a class="onhover_show" style="border: solid black;">Ile</a> with topology</p>
        <div id="coord_4"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1" style="padding-left: 0 !important; font-size: 20px !important; text-align: left !important">Stage 4: Coordinates of <a class="onhover_show" style="border: solid black;">Cys-Tyr</a> with topology</p>
      </div>

    </section>  

    <!-- ######################################################### -->
    <section data-state="Example_3Dstage_Surf">
      <p class="slide-title">Small quiz: visual inspection (Surface) </p>
      <!-- Stage 1 -->
      <div class="box_style_leftbound" style="height: 80% !important; width: 50% !important;">
        <div id="surface_1"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1 " style="font-size: 20px !important; padding-left: 0 !important;">Stage 1: Surface feature of <a class="onhover_show" style="border: solid black;">Cys</a></p>
        <div id="surface_3"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1" style="font-size: 20px !important; padding-left: 0 !important;">Stage 2: Surface feature of <a class="onhover_show" style="border: solid black;">Asn-His</a></p>
      </div>
      
      
      <!-- Stage 2 -->
      <div class="box_style_rightbound" style="height: 80% !important; width: 50% !important;">
        <div id="surface_2" style="height: 40% !important; width: 90% !important"> </div>
        <p class="slide_item_style1" style="padding-left: 0 !important; font-size: 20px !important; text-align: left !important;">Stage 2: Topology of <a class="onhover_show" style="border: solid black;">Cys</a> </p>
        <div id="surface_4"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1" style="padding-left: 0 !important; font-size: 20px !important; text-align: left !important">Stage 4: Topology of <a class="onhover_show" style="border: solid black;">Asn-His</a> </p>
      </div>

    </section>  


    <!-- ######################################################### -->
    <section data-state="Example_3Dstage_Voxel">
      <p class="slide-title">Small quiz: visual inspection (3D voxel) </p>

      <!-- Stage 1 -->
      <div class="box_style_leftbound" style="height: 80% !important; width: 50% !important;">
        <div id="voxel_1"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1 " style="font-size: 20px !important; padding-left: 0 !important;">Stage 1: 3D voxel feature of <a class="onhover_show" style="border: solid black;">Thr</a></p>
        <div id="voxel_3"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1" style="font-size: 20px !important; padding-left: 0 !important;">Stage 2: 3D voxel feature of <a class="onhover_show" style="border: solid black;">His-Ala</a></p>
      </div>
      
      
      <!-- Stage 2 -->
      <div class="box_style_rightbound" style="height: 80% !important; width: 50% !important;">
        <div id="voxel_2" style="height: 40% !important; width: 90% !important"> </div>
        <p class="slide_item_style1" style="padding-left: 0 !important; font-size: 20px !important; text-align: left !important;">Stage 2: 3D voxel feature of <a class="onhover_show" style="border: solid black;">Thr</a> with topology</p>
        <div id="voxel_4"  style="height: 40% !important; width: 90% !important"></div>
        <p class="slide_item_style1" style="padding-left: 0 !important; font-size: 20px !important; text-align: left !important">Stage 4: 3D voxel feature of <a class="onhover_show" style="border: solid black;">His-Ala</a> with topology</p>
      </div>
      
    </section> 


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Feature storage </p>
      <div class="box_style_leftbound" style="width:45% !important; height:30% !important">
        <p class="slide_item_style1">1. Coordinates and surface meshes are heterogeneous features </p>
        <p class="slide_item_style1">2. Voxels and images are homogeneous features </p>
        <p class="slide_item_style1">3. Dual-residue population abundancy depends on the population of dipeptide partners </p>
      </div>

      <div class="box_style_rightbound" style="text-align: left; width:45% !important; height:30% !important">
        <p class="slide_item_style1">4. Sum over dual-residue population resembles the single-residue population </p>
        <p class="slide_item_style1">4. Feature data I/O from the storage medium is the bottleneck of training</p>
        <p class="slide_item_style1">5. The size of 3D voxel data (\(32\times32\times32\) each sample) inflats to over 650 GB (1.8 GB)</p>
      </div>

      <div class="box_style_lowerbound"> 
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Data_structure_Stat.png" style="width: 75%">
        <div class="caption_container">
          <p class="content_subtitle" >Fig 1. Feature storage scheme and population distribution of different residues. </p>
        </div>
      </div>
    </section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Comparison of different feature representations </p>
      <div class="box_style_leftbound">
        <!-- <p class="slide_item_style1 highlight_style1">Mainly focus on the 3D shape and involves as least topology as possible </p> -->
        <p class="slide_item_style1">1. With same amount of training samples (regardless of data size), convergence speed: </p>
        <p class="slide_item_style1" style="margin-left: 8%; margin-right:8%; ">ResNet(Hilbert curve) > PointNet(Coord) > PointNet(Surf) > VoxNet(Voxel) </p>
        <p class="slide_item_style1">2. Single-residue-based classification is solvable, Dual-residue is harder but also solvable (ResNet + Hilbert curve). </p>
        <p class="slide_item_style1">3. ResNet + Hilbert curve achieves good performance, but convergence is unstable (deeper ResNet is even worse, might stem from the fune-tuning of hyperparameters) </p>
        <p class="slide_item_style1 highlight_style1">4. Pure 3D-geometry carries significant structural features </p>
      </div>

      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/FEater_Comparison_ModelDataCombination.png" style="width: 80% !important; ">
        <caption></caption>
      </div>
    </section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Single residue-based classification </p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1">
          <p class="slide_item_style1">1. All of the model-network combinations could achieve good performance on the FEater-Single dataset (Over 90% accuracy) </p>
          <p class="slide_item_style1">2. Coordinate-centric (coordinate and voxel) both make confusion on intrinsic 3D arrangement (Met-Gln, Leu-Ile, Lys-Arg, Thr-Pro)</p>
          <p class="slide_item_style1">3. Coordinate-centric features require the encoding of types (weights) of atoms </p>  
          <p class="slide_item_style1">4. Surface-based methods could capture the atomic radius and potentially bond length features (No Cys-Ser confusion) </p>
        </p>
      </div>
      
      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Result_Single_Res.png" style="height: 80% !important; ">
        <p class="content_subtitle">Fig 1. The performance of different models on the FEater-Single dataset. (A) PointNet + Coord; (B) PointNet + Surf; (C) VoxNet + Voxel; (D) ResNet + Hilbert Curve </p>
      </div>
    </section>
    

    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Dual residue-based classification </p>

      <div class="box_style_leftbound">
        <p class="slide_item_style1">1. ResNet + Hilbert curve almost perfectly solves the dual-residue classification problem (except some MET combinations) </p>
        <p class="slide_item_style1">2. 3D shape efficiency: Coord (PointNet) > Surf (PointNet) > Voxel (VoxNet) </p>
        <p class="slide_item_style1">3. Simple/rigid residue (less degrees of freedom) facilitates the classification (Gly -> Ala -> Pro -> Val)</p>
        <p class="slide_item_style1">4. Flexible residue (more degrees of freedom) makes the classification harder (Met -> Arg -> Gln -> Lys)</p>
      </div>

      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Result_Dual_Res.png" style="height: 80% !important; ">
        <p class="content_subtitle">Fig 1. The performance of different models on the FEater-Dual dataset. (A) PointNet + Coord; (B) PointNet + Surf; (C) VoxNet + Voxel; (D) ResNet + Hilbert Curve </p>
      </div>
    </section>

    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Pretrained models on MD structures </p>
      <div class="box_style_leftbound">
        <p class="slide_item_style1"> 
          <p class="slide_item_style1">1. Three trajectories from DEShaw research are used for the benchmarking of the pretrained models. </p>
          <p class="slide_item_style1">2. The resultant performance remains consistent with the FEater accuracy on the static dataset. </p>
          <p class="slide_item_style1">3. By learning merely from the subtle 3D shapes, the network could extrapolate to the structures from MD trajectories. </p>
          <p class="slide_item_style1 highlight_style1">4. We need to uncouple the 3D structure before engineering features</p>
        </p>
      </div>

      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Trajectory_Accuracies.png" style="width: 95% !important; ">
        <p class="content_subtitle">Fig 1. The performance of pretrained models on 4 types of features on two datasets. </p>
      </div>
    </section>

    
    <!-- ######################################################### -->
    <section>
			<div class="chapter_break_container">
				<p class="chapter_title">Three dimensional dynamic feature and potential application</p>
				<img>
			</div>
		</section>

    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Encoding dynamic features </p>
      <div class="box_style_leftbound" style="text-align: center !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/MDFP_scheme.jpeg" style="width: 80% !important; z-index: -10 !important;">
        <div class="caption_container">
          <p class="content_subtitle"  style="width: 75% !important; ">Fig 1. Useing 3 statistical values to encode a trajectory (MDFP+)</p>
        </div>
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/PointNet-MD-scheme.jpeg" style="width: 80% !important; z-index: -10 !important;">
        <div class="caption_container">
          <p class="content_subtitle" style="width: 75% !important">Fig 2. PointNet-MD used the coordintes/velocity and 3DCNN to predict RDF of solvent </p>
        </div>
      </div>
      
      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Scheme3ddpds.webp" style="width: 75% !important; ">
        <div class="caption_container">
          <p class="content_subtitle">Fig 3. 3DDPD uses the 3D coordinates and PCA to generate the feater vector. </p>
        </div>
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Dynamics_ENM.png" style="width: 100% !important; ">
        <div class="caption_container">
          <p class="content_subtitle">Fig 4. Coarse-grained elastic network models (ENM) takes \(C_{\alpha}\) connected by springs to characterize protein dynamics.</p>
        </div>
      </div>

      <p class="reference_style">
        S. Riniker, Journal of Chemical Information and Modeling, vol. 57, no. 4. American Chemical Society (ACS), pp. 726–741, Apr. 12, 2017. doi: 10.1021/acs.jcim.6b00778. <br>
        C. Li, B. Gilbert, S. Farrell, and P. Zarzycki, Journal of Chemical Information and Modeling, vol. 63, no. 12. American Chemical Society (ACS), pp. 3742–3750, Jun. 12, 2023. doi: 10.1021/acs.jcim.3c00472. <br>
        M. Gorostiola González et al., Journal of Cheminformatics, vol. 15, no. 1. Springer Science and Business Media LLC, Aug. 28, 2023. doi: 10.1186/s13321-023-00745-5. <br>
        F. Zhu et al., Journal of Chemical Information and Modeling, vol. 62, no. 14. American Chemical Society (ACS), pp. 3331–3345, Jul. 11, 2022. doi: 10.1021/acs.jcim.2c00484.
      </p>
    </section>


    <!-- ######################################################### -->
    <section>
      <p class="slide-title">Dynamic feature extraction </p>
      <div class="box_style_leftbound"> 
        <p class="slide_item_style1">1. Grid point \(G_i\) work as observer : monitor particles within its eyesight (cutoff) </p>
        <p class="slide_item_style1">2. Observables are transcribed to a time series \(T_i\) for the computation of dynamic feature \(D_i\) </p>
        <p class="slide_item_style1">3. Observables: \(N_{particle}\), \(B_{particle}\), \(R_g\), \(d_{mean}\), <i>etc</i>. </p>
        <p class="slide_item_style1">4. Arbitrary dynamic feature could be computed on time series \(T_i\) <i>e.g.</i> mean, SD, RMSD</p>
        <p class="slide_item_style1">5. GPU-acceleration (CUDA) is used for the parallelization of the observation</p>

      </div>

      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Nearl_Dyna_features_Scheme.png" style="width: 95% !important; ">
        <p class="content_subtitle">Fig 1. Schematic representation of the dynamic feature generation</p>
      </div>
    </section>


    <!-- ######################################################### -->
    <section>
			<p class="slide-title">Future work </p>
      <div class="box_style_leftbound"> 
        <p class="slide_item_style1">1. Stringent test on the effectiveness of dynamic features in simplified models (FEater classification) </p> 
        <p class="slide_item_style1">2. Finish the MD trajectory featurization pipeline (Shown in Step 2 in Fig 1) </p> 
        <p class="slide_item_style1">3. Benchmark the dynamic featurization speed </p> 
        <p class="slide_item_style1">4. Apply the dynamic features in real applications e.g. protein-ligand binding affinity prediction (Step 1 in Fig 1) </p>
        <p class="slide_item_style1">5. Algorithm to generate dynamic features from scratch in a data-driven manner (Step 3 in Fig 1)</p>

      </div> 	

      <div class="box_style_rightbound" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Overall_workflow.png" style="width: 95% !important; ">
        <p class="content_subtitle">Fig 1. Schematic workflow of dynamic features from MD trajectories to ML applications</p>
      </div>
		</section>


    <!-- ######################################################### -->
    <section data-state="Page_Acknowledgement">
      <p class="slide-title">Acknowledgement</p>
      <div class="box_style_leftbound" >
        <ul style="line-height: 40px !important;">
          <li>Amedeo Caflisch</li>
          <li>Andreas Vitalis</li>
          <li>Julian Widmer, Pablo Vargas</li>
          <li>All members in the Caflisch group</li>
        </ul>
      </div>

      <div class="box_style_leftbound" style="width:50%">
      </div>

      <div class="image-style1">
        <img src="https://miemiemmmm.b-cdn.net/GM_Feb2024/Group_photo.png"   style="width: 100%; height:auto">
      </div>

    </section>

    <!--<section data-state="slide_">-->
    <!--    <p class="slide-title">This is a Template Slide for Demonstration</p>-->
    <!--    <div class="box_style_leftbound">-->
    <!--        <p>This is a Template Main Context1</p>-->
    <!--        <p>This is a Template Main Context2</p>-->
    <!--        <p>This is a Template Main Context3</p>-->
    <!--    </div>-->
    <!--    <p class="reference_style">This is a template reference.</p>-->
    <!--</section>-->

  </div>
</div>



<script type="module">
  ////////////////////////////////////////////////////
  ////// Global Variables and On-load Actions ////////
  ////////////////////////////////////////////////////

  // CDN based module import
  import * as kjera from "https://miemiemmmm.b-cdn.net/GM_Feb2024/modules.js"

  // JSDelivr CDN based module import, after you release the package on Github
  // "https://cdn.jsdelivr.net/gh/miemiemmmm/GM_21Feb2024@main/modules.js

  // TODO: Local module import, for development only
  // import * as kjera from "./modules.js" 

  // NOTE: Replace the USER_NAME and REPO_NAME with your own Github user name and repository name
  //     https://api.github.com/repos/<USER_NAME>/<REPO_NAME>/contents/
  // NOTE: If you are using Private Github Repo to host your slides,
  //     you need to generate a Fine-Grained Personal Access Tokens
  //     with the content access to your repo and replace the GITHUB_FINE_GRAINED_TOKEN with the token
  //     If you are using Public Github Repo, Just comment the Authorization line
  // For more details about Fine-Grained Personal Access Tokens:
  // https://github.blog/2022-10-18-introducing-fine-grained-personal-access-tokens-for-github/
  // const repo_url = "https://api.github.com/repos/miemiemmmm/GM_21Feb2024/contents/";
  // kjera.set_repo(repo_url)
  // Setting up token could improve the amount of traffic you can send to Github
  // kjera.set_token("XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX")


  console.log(">> Preparing the starting environment")
  
  function get_image_url_from_cdn(filename){
    const storage_url = "https://miemiemmmm.b-cdn.net/GM_Feb2024/";
    let returl = storage_url + filename
    console.log("Image url: ", returl)
    return returl
  };

  const img_university_logo = get_image_url_from_cdn("uzh_logo_e_pos_web_main.jpg");
  const img_welcome = get_image_url_from_cdn("snapshot.png");
  const img_chapter_break = get_image_url_from_cdn("welcome.png");

  /////////////////////////////////////////////////
  //////////// On-load Functions to do ////////////
  /////////////////////////////////////////////////
  // Set up the background picture of the welcome slide
  await kjera.setupImage("welcome_bgimage", img_welcome);
  
  // Manually set up elements outside the Reveal.js framework
  // One time asynchronous function to manipulate the DOM
  (async function(){
    // Setting up the university logo on the top left corner
    var imgdiv = document.createElement('img');
    document.body.appendChild(imgdiv);
    imgdiv.classList.add('institute_logo');
    imgdiv.src = img_university_logo;
  })();


  Reveal.initialize({
    // Set the theme to white
    theme: 'white',
    // Set the transition style to slide
    transition: 'convex',
    backgroundTransition: "zoom"
  });

  
  console.log(">> Initializing the reveal.js framework");
  //////////// A Typical Animation Function ////////////
	// function animate() {
	//     requestAnimationFrame(animate);
	//     renderer.render(scene, camera);
	// }
	// animate();
	/////////////////////////////////////////////////////

  Reveal.addEventListener('slidechanged', function(event) {
    if (event.currentSlide && event.currentSlide.getAttribute('data-state') == "Example_3Dstage_Coord"){
      if (document.getElementById("coord_1").querySelector("canvas") == null){
        kjera.initPLYObject("coord_1", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewPureCoord_ILE.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("coord_2").querySelector("canvas") == null){
        kjera.initPLYObject("coord_2", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewCoord_ILE.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Put the camera far away from the object
          camera.position.set(0, 0, 100);
          camera.updateProjectionMatrix();
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("coord_3").querySelector("canvas") == null){
        kjera.initPLYObject("coord_3", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewPureCoord_CYSTYR.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("coord_4").querySelector("canvas") == null){
        kjera.initPLYObject("coord_4", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewCoord_CYSTYR.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          camera.position.set(0, 0, 100);
          camera.updateProjectionMatrix();
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      var found_onhover_show = event.currentSlide.querySelectorAll( '.onhover_show' );
      for (var i = 0; i < found_onhover_show.length; i++) {
        found_onhover_show[i].onclick = function(){ 
          console.log("Removing the onhover_show class from the p tags in this slide")
          this.classList.remove("onhover_show")
        }
      }
    }
  })


  Reveal.addEventListener('slidechanged', function(event) {
    if (event.currentSlide && event.currentSlide.getAttribute('data-state') == "Example_3Dstage_Surf"){
      // Check if the stage div contains canvas or not
      if (document.getElementById("surface_1").querySelector("canvas") == null){
        kjera.initPLYObject("surface_1", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewSurf_CYS.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("surface_2").querySelector("canvas") == null){
        kjera.initPLYObject("surface_2", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewCoord_CYS.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Put the camera far away from the object
          camera.position.set(0, 0, 100);
          camera.updateProjectionMatrix();
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("surface_3").querySelector("canvas") == null){
        kjera.initPLYObject("surface_3", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewSurf_ASNHIS.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("surface_4").querySelector("canvas") == null){
        kjera.initPLYObject("surface_4", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewCoord_ASNHIS.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Put the camera far away from the object
          camera.position.set(0, 0, 100);
          camera.updateProjectionMatrix();
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      // Click the element to remove the onhover_show class for the p tags in this slide
      var found_onhover_show = event.currentSlide.querySelectorAll( '.onhover_show' );
      for (var i = 0; i < found_onhover_show.length; i++) {
        found_onhover_show[i].onclick = function(){ 
          console.log("Removing the onhover_show class from the p tags in this slide")
          this.classList.remove("onhover_show")
        }
      }
    }
  });


  Reveal.addEventListener('slidechanged', function(event) {
    if (event.currentSlide && event.currentSlide.getAttribute('data-state') == "Example_3Dstage_Voxel"){
      // Check if the stage div contains canvas or not
      if (document.getElementById("voxel_1").querySelector("canvas") == null){
        // Initialize the 3D scene
        kjera.initPLYObject("voxel_1", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewPure_THR.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }

      if (document.getElementById("voxel_2").querySelector("canvas") == null){
        kjera.initPLYObject("voxel_2", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewExample_THR.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Put the camera far away from the object
          camera.position.set(0, 0, 100);
          camera.updateProjectionMatrix();
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("voxel_3").querySelector("canvas") == null){
        kjera.initPLYObject("voxel_3", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewPure_HISALA.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      if (document.getElementById("voxel_4").querySelector("canvas") == null){
        kjera.initPLYObject("voxel_4", "https://miemiemmmm.b-cdn.net/GM_Feb2024/ViewExample_HISALA.ply").then((ret)=>{
          var scene = ret[0]
          var renderer = ret[1]
          var camera = ret[2]
          var light = ret[3]
          // Put the camera far away from the object
          camera.position.set(0, 0, 100);
          camera.updateProjectionMatrix();
          // Animation loop
          function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
          }
          console.log("Do the animation")
          animate();
        })
      }
      // Click the element to remove the onhover_show class for the p tags in this slide
      var found_onhover_show = event.currentSlide.querySelectorAll( '.onhover_show' );
      for (var i = 0; i < found_onhover_show.length; i++) {
        found_onhover_show[i].onclick = function(){ 
          console.log("Removing the onhover_show class from the p tags in this slide")
          this.classList.remove("onhover_show")
        }
      }
    } 
  });


  /////////////////////////////////////////////
  ////// Auxiliary and onchange functions /////
  /////////////////////////////////////////////
  Reveal.addEventListener( 'slidechanged', function( event ) {
    // Add page number to the footer
    var pageNumber = event.indexh + 1;
    var totalPages = Reveal.getTotalSlides();
    var pageString = pageNumber + '/' + totalPages;
    var pageNumberElement = document.querySelector( '.page_number' );
    if ( pageNumberElement ) {
      pageNumberElement.innerHTML = pageString;
      pageNumberElement.style.zIndex = 5
    } else {
      var pagediv = document.createElement( 'div' );
      pagediv.classList.add( 'page_number' );
      pagediv.innerHTML = pageString;
      pagediv.style.zIndex = 5;
      document.body.appendChild( pagediv );
    }

    const viewportWidth = window.innerWidth || document.documentElement.clientWidth;
    const viewportHeight = window.innerHeight || document.documentElement.clientHeight;
    console.log("ViewPort Width:", viewportWidth, "/ Height", viewportHeight);

    // Setup slides for chapter break
    var found_chapterbreak = event.currentSlide.querySelector( '.chapter_break_container' );
    var found_chapterbreakimg = event.currentSlide.querySelector( '.chapter_break_container img' );
    if ( found_chapterbreak && found_chapterbreakimg.src.slice(0,4) !== "data") {
      found_chapterbreakimg.className = "bgimg_style_rsmall"
      found_chapterbreakimg.src = img_chapter_break
      found_chapterbreakimg.style.zIndex = -10
    }
  });

  // Laser pointer function for the slides
  // Enable/disable the laser pointer by pressing the "1" key
  const laserPointer = document.querySelector('.laser-pointer');
  var mouseX = 0;   // Global variable to store mouse position
  var mouseY = 0;
  var usingLaser = false;  // Global variable to store the use of laser pointer
  document.addEventListener('keydown', (event) => {
    if (event.key == "1" && !usingLaser){
      laserPointer.style.opacity = 1; 
      usingLaser=true; 
      $('body').css('cursor', 'none'); 
      laserPointer.style.left = mouseX - laserPointer.clientWidth / 2 + 'px';
      laserPointer.style.top = mouseY - laserPointer.clientHeight / 2 + 'px';
    } else if (event.key == "1" && usingLaser) {
      laserPointer.style.opacity = 0;
      usingLaser=false; 
      $('body').css('cursor', 'default');
    }
  });

  // Record the pointer position and update the laser pointer position
  document.addEventListener('mousemove', (event) => {
    mouseX = event.clientX;
    mouseY = event.clientY;
    if (usingLaser) {
      laserPointer.style.left = event.clientX - laserPointer.clientWidth / 2 + 'px';
      laserPointer.style.top = event.clientY - laserPointer.clientHeight / 2 + 'px';
    }
  });

  // Onhover zooming functions for gallery items
  $(".gallery-item img, .gallery-item2 img, .gallery-item3 img").hover(
    // Translate the figcaption by 1/2 of the image height 
    function() {
      let img_height = $(this).height();
      $(this).next().css({"transform": "translateY("+img_height/2+"px)"});
      $(this).css({"z-index": 999});
    },
    function() {
      $(this).next().css({"transform": "translateY(0px)"});
      $(this).css({"z-index": 0});
    }
  )

  // Popup a one-time notification above the "controls-arrow" 
  var arrow_clicked = false;
  document.addEventListener('DOMContentLoaded', function() {
    var notification = document.createElement('div');
    notification.innerHTML = "Click the arrow<br> or right key";
    notification.classList.add('content_subtitle');
    notification.classList.add('slideplay_notification');
    document.body.appendChild(notification);
    
    // Onclick removal of the play notification
    $(".controls-arrow").on("click", function(){
      if (!arrow_clicked){
        arrow_clicked = true;
        notification.style.display = "none";
      }
    });
    document.addEventListener('keydown', (event) => {
      if (event.key == "ArrowRight" && !arrow_clicked){
        arrow_clicked = true;
        notification.style.display = "none";
      }
    });
    notification.onclick = function(){
      notification.style.display = "none";
    }
  });

</script>

</body>

</html>
