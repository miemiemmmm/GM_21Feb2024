<!DOCTYPE html>
<html lang="en">


<head>
  <meta charset="UTF-8" />
  <title>Group Meeting Yang Zhang</title>
  <script type="module">
    // Load the three.js for 3d object visualization
    import * as THREE from  "https://cdn.jsdelivr.net/npm/three@0.127.0/build/three.module.js"
    import { OrbitControls } from "https://cdn.jsdelivr.net/npm/three@0.127.0/examples/jsm/controls/OrbitControls.js"
    import { PLYLoader } from "https://cdn.jsdelivr.net/npm/three@0.127.0/examples/jsm/loaders/PLYLoader.js"
    window.THREE = THREE;
    window.OrbitControls = OrbitControls;
    window.PLYLoader = PLYLoader
  </script>

  <!-- Load reveal.js -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/reveal.min.css" integrity="sha512-V5fKCVKOFy36w8zJmLzPH5R6zU6KvuHOvxfMRczx2ZeqTjKRGSBO9yiZjCKEJS3n6EmENwrH/xvSwXqxje+VVA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/js/reveal.min.js" integrity="sha512-QYXU3Cojl94ZRiZRjUZpyg1odj9mKTON9MsTMzGNx/L3JqvMA3BQNraZwsZ83UeisO+QMVfFa83SyuYYJzR9hw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <!-- Load jQuery-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.9.1/jquery.min.js" integrity="sha512-jGR1T3dQerLCSm/IGEGbndPwzszJBlKQ5Br9vuB0Pw2iyxOy+7AK+lJcCC8eaXyz/9du+bkCy4HXxByhxkHf+w==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <!-- Load 3DMol.js -->
  <script src="https://3Dmol.org/build/3Dmol-min.js"></script>
  <script src="https://3Dmol.org/build/3Dmol.ui-min.js"></script>

  <!-- Load MathJax for labex representation -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS_HTML"></script>

  <!-- Load the customized modules and style sheets -->
  <script type="module" src="https://miemiemmmm.b-cdn.net/CM_Feb2024/modules.js"></script>
  <link rel="stylesheet" type="text/css" href="https://miemiemmmm.b-cdn.net/CM_Feb2024/styles.css">

</head>


<body>
<div class="reveal">
  <!-- Add laser pointer object -->
  <div class="laser-pointer"></div>

  <!-- Welcome page: Set title, seminar info and background image (handled in JavaScript part) -->
  <div class="slides" id="slide_container">
    <section data-state="Title_Page">
      <div style="position:relative; height:40%; width:100%; top:10%">
        <p class="presentation_title" style="color:#1C226B; -webkit-text-stroke: 1.5px blue;">Benchmarking 3D Shape-Based Recognition for Flexible Building Blocks</p>
      </div>

      <p class="presentation_info">Yang Zhang</p>
      <p class="presentation_info">Caflisch Group</p>
      <p class="presentation_info">21st Feb 2024</p>
      <p class="presentation_info">Department of Biochemistry</p>
      <img id="welcome_bgimage" class="bgimg_style_welcome">
    </section>

    <!-- 
      Title and abstract
      Benchmarking 3D Shape-Based Recognition for Flexible Building Blocks
      Atoms are in constant motion, and all but the simplest molecules are flexible, thus being justly called deformable or soft objects. With the eventual goal of deciphering the 3D motion of molecules using machine learning (ML), a fundamental problem arises beforehand: how efficiently can a data-driven model abstract the shape heterogeneity of flexible molecular building blocks, which is manifest also in structural databases like the PDB, while correctly recognizing their identities? This core task will inevitably remain a fundamental component of deployed models, much like basic object recognition and tracking are basic components of the automated mining of video data. In molecules, the design of features is a critical step for many tasks from protein design to drug discovery. Naturally, features must carry task-specific information, yet the methods used for composing them and the role of molecular geometry (shape) in these processes are rarely defined explicitly. In this work, we establish a standard workflow to compare different combinations of standard ML models with various molecular representations. We created a benchmark dataset containing substantial heterogeneity for a given label to offer a platform for rigorous performance comparisons. Our findings reveal that, while it is feasible to train general-purpose models, their efficiency and performance ceiling can differ. We also demonstrate that pretrained models are capable of acquiring transferable knowledge by deploying them to data taken from dynamic trajectories.
     -->

    <!-- Template page--> 
    <!-- <section data-state="slide_">
      <p class="slide-title">This is a Template Slide for Demonstration</p>
      <div class="box_style_t20l0h100w50">
        <p>This is a Template Main Context1</p>
        <p>This is a Template Main Context2</p>
        <p>This is a Template Main Context3</p>
      </div>
      <p class="reference_style">This is a template reference.</p>
    </section> -->

    <section data-state="slide_OutlinePage">
      <p class="slide-title" style="font-size: 30px !important; ">Outline</p>
      <div class="box_style_t20l0h100w100">
        <p class="slide_item_style1" style="font-size: 30px !important; ">1: Introduction </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">2: Three dimensional molecular representations </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">3: Benchmarking the 3D shape perception  </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">4: Three dimensional dynamic feature and potential application </p>
        <p class="slide_item_style1" style="font-size: 30px !important; ">5: Future work </p>
      </div>

      <div class="image-style1">
        <!-- <img src="welcome.png" class="bgimg_style_subsection" style="position: absolute; top:10px; right:-300px; opacity:0.25; transform: rotate(-30deg); height: 700px; width: auto; filter: blur(5px);" > -->
        <img src="welcome.png" class="bgimg_style_rbig">
      </div>
    </section>


    <!--
    Page template for chapter break.
    The class name of the <div> includes:
        chapter_break_container
    The <img> is automatically set to the default image for chapter break
    -->

    <section>
			<div class="chapter_break_container">
				<p class="chapter_break">Introduction</p>
				<img>
			</div>
		</section>

    <section>
      <p class="slide-title">3D shape-based training</p>
      <div class="box_style_t20l0h100w50">
        <p class="slide_item_style1" style="padding-left: 0 !important; ">In computer vision field, 3D shape-based training is a fundamental task. The 3D shape-based training can be categorized into several types:</p>
        <p class="slide_item_style1">1. Point cloud-based </p>
        <p class="slide_item_style1">2. Voxel-based  </p>
        <p class="slide_item_style1">3. Surface-based </p>
        <p class="slide_item_style1">4. Hilbert curve-based dimension reduction </p>
        <p class="slide_item_style1">5. Point 5: Example Item </p>
      </div>

      <div class="box_style_t50r75h100c">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/PointNet_pointcloud.png" style="width: 80% !important; ">
        <p class="content_subtitle" >Fig 1. Point cloud </p>
      </div>
      <!-- PointNet_pointcloud.png -->
    </section> 

    <section>
      <p class="slide-title">Diverse 3D molecular representation</p>
      <div class="box_style_t20l0h100w50">
        <p class="slide_item_style1">1. Point cloud is a unordered set of points in 3D space however, molecular coordinates typically requires a fixed order. </p>
        <p class="slide_item_style1">2. Surface mesh could be generated by marching cubes (Fig 1) </p>
        <p class="slide_item_style1">3. 3D voxel compuated by distance-based gaussian mapping (Fig 2) </p>


      </div>

      <div class="box_style_t50r75h100c">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/MarchingCubesScheme.png" style="width: 80% !important; ">
        <p class="content_subtitle" style="display: flex !important; width:80% !important" >Fig 1. Schematic representation of marching cubes algorithm </p>
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/gaussian_mapping.png" style="width: 80% !important; ">
        <p class="content_subtitle" style="display: flex !important; width:80% !important" >Fig 2. Distance-based gaussian mapping</p>
      </div>
      <!-- <img src="welcome.png" class="bgimg_style_rbig" > -->
      <p class="reference_style">
        B. Y. Chen, PLoS Computational Biology, vol. 10, no. 8. Public Library of Science (PLoS), p. e1003792, Aug. 28, 2014. doi: 10.1371/journal.pcbi.1003792.<br>
        N. Renaud et al., Nature Communications, vol. 12, no. 1. Springer Science and Business Media LLC, Dec. 03, 2021. doi: 10.1038/s41467-021-27396-0.

      </p>
    </section>

    <section>
      <p class="slide-title">Current extensions to dynamic contents</p>
      <div class="box_style_t20l0h100w50">
        <p class="slide_item_style1">Human-motion analysis / pose recognition </p>
        <p class="slide_item_style1">Self-driving car </p>
        <p class="slide_item_style1">Robot path planning </p>
        <p class="slide_item_style1" style="font-weight: bold;">\(\cdot \cdot \cdot\)</p>
        <p class="slide_item_style1 content_subtitle">Of course: molecular dynamics</p>
        
      </div>

      <div class="box_style_t75l25w50c" style="text-align: center !important;z-index: -100 !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/snapshot.png" style="width: 70% !important; ">
        
      </div>

      <div class="box_style_t20r75w50">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Human_motion.png" style="width: 80% !important; ">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/FoggyScenes_pipeline.png" style="width: 80% !important; ">
      </div>

      <p class="reference_style">
        Petrovich, M., Black, M. J., & Varol, G. (2022). arXiv. https://doi.org/10.48550/ARXIV.2204.14109<br>
        Wrenninge, M., & Unger, J. (2018). arXiv. https://doi.org/10.48550/ARXIV.1810.08705
      </p>
    </section>

    
    <section>
			<div class="chapter_break_container">
				<p class="chapter_break">Three dimensional molecular representations</p>
				<img>
			</div>
		</section>

    <section>
      <p class="slide-title">Do not be fooled by the graph-based representation! </p>
      <!-- 
        TODO: List somethings for different representations with single-dual residue
       -->

    </section> 
    

    <section>
      <p class="slide-title">Featurization of single/dual-residues</p>

    </section>


    <section>
			<div class="chapter_break_container">
				<p class="chapter_break">Benchmarking the 3D shape perception</p>
				<img>
			</div>
		</section>


    <section>
      <p class="slide-title">FEater dataset</p>
      <div class="box_style_t20l0h100w50">
        <p class="slide_item_style1">FEater (<a style="font-weight: bold;">F</a>lexibility and <a style="font-weight: bold;">E</a>lasticity <a style="font-weight: bold;">A</a>ssessment 
          <a style="font-weight: bold;">T</a>ool for <a style="font-weight: bold;">E</a>ssential <a style="font-weight: bold;">R</a>esidues) can be abbreviated in multiple ways
        </p>
        <div class="">
          <p class="slide_item_style1">1. Contains two datasets FEater-Single and FEater-Dual </p>
          
          <p class="slide_item_style1">2. Each dataset contains over 8 million structures </p>
          <p class="slide_item_style1">3. FEater-Single has 20 tags and FEater-Dual has 400 tags (Combination of 20 amino acids)</p>
          <p class="slide_item_style1">4. Source PDB structure are from PDBBind dataset </p>
        </div>

      </div> 
        
      <div class="box_style_t50r75h100c" >
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/FEater_Standard_workflow.png" style="width: 95% !important; ">
        <p class="content_subtitle">Fig 1. </p>
        <p class="slide_item_style1"> </p>
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/FEater_draftlogo.png" style="height: 50% !important; ">
        <p class="content_subtitle">Fig 2. Drafted logo for FEater; Designed by DALL\(\cdot\)E-3 </p>
      </div>
    </section>

    <section>
      <p class="slide-title">FEater-Single and FEater-Dual dataset</p>
      <div class="box_style_t20l0h100w50" style="text-align: center !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/DataDriven_aligned3DMols.png" style="height: 300px; ">
      </div>

      <div class="box_style_t20r75w50" style="text-align: center !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/DataDrivenVisualization.png" style="height: 300px; ">
      </div>

    </section>


    <section>
      <p class="slide-title">Feature storage </p>
      <div class="box_style_t20l0h100w50 content_subtitle" style="width:45% !important; height:30% !important">
        <!-- <p class="slide_item_style1"> </p> -->
        <p class="slide_item_style1">Coordinates/Meshes are heterogeneous features </p>
        <p class="slide_item_style1">Voxels/Images are homogeneous features </p>
        <p class="slide_item_style1">Dual-residue population abundancy largely depends on the population of the population of partners </p>
      </div>

      <div class="box_style_t20r75w50 content_subtitle" style="text-align: left; width:45% !important; height:30% !important">
        <!-- <p class="slide_item_style1">All of combinations are identified </p> -->
        <p class="slide_item_style1">Feature data I/O from the storage medium is the bottleneck of training</p>
        <p class="slide_item_style1">The size of 3D voxel data \(32\times32\times32\) inflats to 800 GB level</p>
        

      </div>

      <div class="box_style_t75l50w100c" style="text-align: center !important; top:80% !important;"> 
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Data_structure_Stat.png" style="width: 75%">
        <!-- <p class="content_subtitle" >Feature storage scheme and population distribution of different residues. </p> -->
      </div>
    </section>


    <section>
      <p class="slide-title">Various molecular representations VS general-purposed networks </p>
      <div class="box_style_t20l0h100w50 content_subtitle">
        <p class="slide_item_style1">1. Coordinates could be viewed as point cloud and processed by <a style="font-weight: bold;">PointNet</a></p>
        <p class="slide_item_style1">2. Surface mesh vertices could be viewed as point cloud (<a style="font-weight: bold;">PointNet too</a>)</p>
        <p class="slide_item_style1">3. Property density map could be viewed as 3D voxel (<a style="font-weight: bold;">VoxNet</a>)</p>
        <p class="slide_item_style1">4. Transforming 3D voxel to 2D via spacefilling curve could be viewed as image (<a style="font-weight: bold;">ResNet</a>)</p>
      </div>

      <div class="box_style_t20r75w50">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/FEater_Toc.png" style="z-index: -1; width:65% !important" >
      </div>
    </section>


    <section>
      <p class="slide-title">Comparison of different feature representations </p>
      <div class="box_style_t20l0h100w50">
        <p class="slide_item_style1">1. Single-residue-based classification is solvable. </p>
        <p class="slide_item_style1">2. Dual-residue-based classification is solvable in theory</p>
        <p class="slide_item_style1">3. With same amount of data (regardless of data size), convergence speed: ResNet(Hilbert curve) > PointNet(Coord) > PointNet(Surf) > VoxNet(Voxel) </p>
        <p class="slide_item_style1">3. </p>
        <p class="slide_item_style1">4. </p>

      </div>

      <div class="box_style_t20r75w50" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/FEater_Comparison_ModelDataCombination.png" style="width: 80% !important; ">
        <caption></caption>
      </div>
    </section>


    <section>
      <p class="slide-title">Single residue-based classification </p>
      <div class="box_style_t20l0h100w50">
        <p class="slide_item_style1">
          1. 
        </p>
      </div>
      
      <div class="box_style_t50r75h100c" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Result_Single_Res.png" style="height: 80% !important; ">
        <p class="content_subtitle">Fig 1. The performance of different models on the FEater-Single dataset </p>
      </div>
    </section>
    
    <section>
      <p class="slide-title">Dual residue-based classification </p>

      <div class="box_style_t20l0h100w50">
        <p class="slide_item_style1">1. </p>
        <p class="slide_item_style1">2. 

        </p>
        <p class="slide_item_style1">ResNet + 2D Hilbert curve almost fully captures the information of the 3D voxel</p>

      </div>

      <div class="box_style_t50r75h100c" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Result_Dual_Res.png" style="height: 80% !important; ">
        <p class="content_subtitle">Fig 1. The performance of different models on the FEater-Dual dataset</p>
      </div>
    </section>

    


    <section>
			<div class="chapter_break_container">
				<p class="chapter_break">Three dimensional dynamic feature and potential application</p>
				<img>
			</div>
		</section>

    <section>
      <p class="slide-title">Encoding dynamic features </p>
      <div class="box_style_t20l0h100w50"> 
        <p class="slide_item_style1">1. </p>
      </div>

      <div class="box_style_t20l0h100w50" style="text-align: center !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/MDFP_scheme.jpeg" style="width: 90% !important; z-index: -10 !important;">
        <p class="content_subtitle"  style="width: 90% !important; z-index: -10 !important;">MDFP+</p>
        <p class="slide_item_style1"> </p>
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/PointNet-MD-scheme.jpeg" style="width: 90% !important; z-index: -10 !important;">
        <div style="text-align: center !important;"><div class="content_subtitle"  style="width: 90% !important; z-index: -10 !important;">PointNet-MD</div></div>
      </div>

      <div class="box_style_t50r75h100c" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Scheme3ddpds.webp" style="width: 90% !important; ">
        <caption></caption>
      </div>

      <p class="reference_style">
        S. Riniker, Journal of Chemical Information and Modeling, vol. 57, no. 4. American Chemical Society (ACS), pp. 726–741, Apr. 12, 2017. doi: 10.1021/acs.jcim.6b00778.<br>
        C. Li, B. Gilbert, S. Farrell, and P. Zarzycki, Journal of Chemical Information and Modeling, vol. 63, no. 12. American Chemical Society (ACS), pp. 3742–3750, Jun. 12, 2023. doi: 10.1021/acs.jcim.3c00472.<br>
        M. Gorostiola González et al., Journal of Cheminformatics, vol. 15, no. 1. Springer Science and Business Media LLC, Aug. 28, 2023. doi: 10.1186/s13321-023-00745-5.<br>
      </p>
    </section>


    <section>
      <p class="slide-title">Dynamic feature extraction </p>
      <div class="box_style_t20l0h100w50"> 
        <p class="slide_item_style1">1. Grid point \(G_i\) work as observer to monitor a number of frames within its eyesight (cutoff) </p>
        <p class="slide_item_style1">2. Observables are transcribed to a time series for the computation of dynamic feature of point \(G_i\) </p>
        <p class="slide_item_style1">3. GPU-acceleration (CUDA) is used for the parallelization of the observation</p>
        <p class="slide_item_style1">4. Arbitrary dynamic feature could be computed by the time series of point \(G_i\) </p>
      </div>

      <!-- 
        
       -->
      <div class="box_style_t50r75w50c" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Nearl_Dyna_features_Scheme.png" style="width: 95% !important; ">
        <p class="content_subtitle">Fig 1. Schematic representation of the dynamic feature generation</p>
      </div>
    </section>



    

    <section>
			<p class="slide-title">Future work </p>
      <div class="box_style_t20l0h100w50"> 
        <p class="slide_item_style1">1. Stringent test of the dynamic features in toy model (FEater classification)</p>
        <p class="slide_item_style1">2. Featurize the prepared MD trajectories (Step 1 in Fig 1) </p>
        <p class="slide_item_style1">3. Apply the dynamic features in real applications e.g. protein-ligand affinity prediction (Step 1 in Fig 1) </p>
        <p class="slide_item_style1">4. Algorithm to generate dynamic features from scratch (Step 2,3 in Fig 1)</p>

      </div> 	


      <div class="box_style_t50r75w50c" style="z-index: -10 !important;">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Overall_workflow.png" style="width: 95% !important; ">
        <p class="content_subtitle">Fig 1. Overall workflow for the information flow of the dynamic features</p>
      </div>
		</section>

    <section data-state="Page_Acknowledgement">
      <p class="slide-title">Acknowledgement</p>
      <div class="box_style_t20l0h100w50">
        <ul class="">
          <li>Amedeo Caflisch</li>
          <li>Andreas Vitalis</li>
          <li>Julian Widmer, Pablo Vargas</li>
          <li>All members in the Caflisch group</li>
        </ul>
      </div>

      <div class="box_style_t20l0h100w50" style="width:50%">
      </div>

      <div class="image-style1">
        <img src="https://miemiemmmm.b-cdn.net/CM_Feb2024/Group_photo.png"   style="width: 100%; height:auto">
      </div>

    </section>

    <!--<section data-state="slide_">-->
    <!--    <p class="slide-title">This is a Template Slide for Demonstration</p>-->
    <!--    <div class="box_style_t20l0h100w50">-->
    <!--        <p>This is a Template Main Context1</p>-->
    <!--        <p>This is a Template Main Context2</p>-->
    <!--        <p>This is a Template Main Context3</p>-->
    <!--    </div>-->
    <!--    <p class="reference_style">This is a template reference.</p>-->
    <!--</section>-->

  </div>
</div>



<script type="module">
  import * as kjera from "https://miemiemmmm.b-cdn.net/CM_Feb2024/modules.js"
  // "https://cdn.jsdelivr.net/gh/miemiemmmm/GM_21Feb2024@main/modules.js
  // import * as kjera from "./modules.js" // Using local modules.js, for development only

  ////////////////////////////////////////////////////
  ////// Global Variables and On-load Actions ////////
  ////////////////////////////////////////////////////

  // NOTE: If you are using Private Github Repo to host your slides,
  //       you need to generate a Fine-Grained Personal Access Tokens
  //       with the content access to your repo and replace the GITHUB_FINE_GRAINED_TOKEN with the token
  //       If you are using Public Github Repo, Just comment the Authorization line
  // For more details about Fine-Grained Personal Access Tokens:
  // https://github.blog/2022-10-18-introducing-fine-grained-personal-access-tokens-for-github/
  const github_auth = {
    // Authorization: "Bearer GITHUB_FINE_GRAINED_TOKEN",
    Accept: "application/vnd.github+object",
  };
  // NOTE: Replace the USER_NAME and REPO_NAME with your own Github user name and repository name
  // https://api.github.com/repos/<USER_NAME>/<REPO_NAME>/contents/
  const repo_url = "https://api.github.com/repos/miemiemmmm/GM_21Feb2024/contents/";
  
  kjera.set_repo(repo_url)
  // Setting up token could improve the amount of traffic you can send to Github
  kjera.set_token("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")


  console.log("######################################")
  console.log(">> Preparing the starting environment")
  console.log("^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^")

  const PRELOAD_FIGURES = false
  const FIGURES = {}
	if (PRELOAD_FIGURES == true){
    console.log("Before get all images <<<<<<<<<<<<<")
    kjera.getAllImages(FIGURES)
    console.log("After get all images <<<<<<<<<<<<<")
	}

  function get_image_url_from_storage(filename){
    let storage_url = "https://miemiemmmm.b-cdn.net/CM_Feb2024/"
    let returl = storage_url + filename
    console.log("Getting the image url: ", returl)
    return returl
  }
  // let read_key = "f2134ecf-99e0-4edd-9af74cef58ed-5a60-4818"
  // https://miemiemmmm.b-cdn.net/uzh_logo_e_pos_web_main.jpg
  // https://miemiemmmm.b-cdn.net/CM_Feb2024/Group_photo.png
  //  + "?AccessKey="+read_key


  // Whether or not to PRELOAD all images from the given Github Repo
  // NOTE: Perticularly useful when you do the final presentation
  //       You might want to disable it when you are still developing your slides


  const img_university_logo = get_image_url_from_storage("uzh_logo_e_pos_web_main.jpg")
  const img_welcome = get_image_url_from_storage("welcome.png")
  const img_chapter_break = get_image_url_from_storage("welcome.png")

  // Default background color for all 3D scenes
  // Use the HEXDEC color code without the "#" sign
  const scene_bgcolor = "FFF9DE";

	//////////// A Typical Animation Function ////////////
	// function animate() {
	//     requestAnimationFrame(animate);
	//     renderer.render(scene, camera);
	// }
	// animate();
	/////////////////////////////////////////////////////

  // Note sure if this is needed or not 
  function reset_canvas(parent_div, viewer){
    // The canvas size is reset for the 3Dmol viewer if you switch slides
    // Reset the canvas size when you go back to the slide that contains the 3Dmol viewer
    var container = document.getElementById(parent_div);
    // var width = container.clientWidth;
    var width = container.offsetWidth;
    var height = container.clientHeight;
    console.log("Set the width/height of the canvas: ",parent_div, "height/width:", height, width)
    viewer.setWidth(width);
    viewer.setHeight(height);
    viewer.render();
    // $("#"+parent_div+" canvas").css({"position": "relative", "width":"100%", "height": "100%"})
  }


  /////////////////////////////////////////////////
  //////////// On-load Functions to do ////////////
  /////////////////////////////////////////////////

  // Set up the background picture of the welcome slide
  await kjera.setupImage("welcome_bgimage", img_welcome)
  
  // setupImage("welcome_bgimage", repo_url + img_welcome)



    // Declare global image variables for potential reuse
    // var univ_logo
  var b64_chapter_break


  // Set university logo
  (async ()=>{
    console.log("The university logo is: ", img_university_logo)
    var imgdiv = document.createElement('img');
    document.body.appendChild(imgdiv);
    imgdiv.classList.add('univ_logo');
    imgdiv.id = "univ_logo"
    // await kjera.setupImage("univ_logo", img_university_logo)
    
    imgdiv.src = img_university_logo;
    // console.log("The chapter break image is: ", img_chapter_break)
    // let test = await kjera.getImageb64(img_chapter_break);
    // console.log("The test is: ", test)
    // console.log(img_chapter_break)
    // b64_chapter_break = await kjera.getImageb64(repo_url + img_chapter_break);
  })()






  Reveal.initialize({
    // Set the theme to white
    theme: 'white',
    // Set the transition style to slide
    transition: 'convex',
    backgroundTransition: "zoom"
  });


  console.log("######################################")
  console.log(">> Initializing the reveal.js framework")
  console.log("^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^")

  /////////////////////////////////////////////
  ////// Auxiliary and onchange functions /////
  /////////////////////////////////////////////
  Reveal.addEventListener( 'slidechanged', function( event ) {
    // Add page number to the footer
    var pageNumber = event.indexh + 1;
    var totalPages = Reveal.getTotalSlides();
    var pageString = pageNumber + '/' + totalPages;
    var pageNumberElement = document.querySelector( '.page-number' );
    if ( pageNumberElement ) {
      pageNumberElement.innerHTML = pageString;
      pageNumberElement.style.zIndex = 5
    } else {
      var pagediv = document.createElement( 'div' );
      pagediv.classList.add( 'page-number' );
      pagediv.innerHTML = pageString;
      pagediv.style.zIndex = 5
      document.body.appendChild( pagediv );
    }

    // ??????????????????
    // var symbol_fig = document.querySelector( '.symbol_fig' );
    // if ( symbol_fig ) {
    //     symbol_fig.src = image_symbol
    // } else {
    //     var symboldiv = document.createElement( 'img' );
    //     symboldiv.classList.add( 'symbol_fig' );
    //     symboldiv.src = image_symbol;
    //     symboldiv.style.zIndex = 0
    //     document.body.appendChild(symboldiv)
    // }

    const viewportWidth = window.innerWidth || document.documentElement.clientWidth;
    const viewportHeight = window.innerHeight || document.documentElement.clientHeight;
    console.log("ViewPort Width:", viewportWidth, "/ Height", viewportHeight);
    // $("#slide_container").css({"width": String(viewportWidth*0.45)+"px"})

    // setup break slide
    var found_chapterbreak = event.currentSlide.querySelector( '.chapter_break_container' );
    var found_chapterbreakimg = event.currentSlide.querySelector( '.chapter_break_container img' );
    if ( found_chapterbreak && found_chapterbreakimg.src.slice(0,4) !== "data") {
      found_chapterbreakimg.className = "bgimg_style_rsmall"
      found_chapterbreakimg.src = img_chapter_break
      found_chapterbreakimg.style.zIndex = -10
    }
  });

  // Laser pointer function for the slides
  const laserPointer = document.querySelector('.laser-pointer');
  var usingLaser = false;
  // Enable/disable the laser pointer on holding the 'L' key (key code 76)
  document.addEventListener('keydown', (event) => {
    if (event.key == "1" && !usingLaser){
      laserPointer.style.opacity = 1;
      usingLaser=true
      $('body').css('cursor', 'none');
      laserPointer.style.left = -100+"px";
      laserPointer.style.top = -100+"px";
    } else {
      laserPointer.style.opacity = 0;
      usingLaser=false
      $('body').css('cursor', 'default');
    }
  });

  // Move the laser pointer with the mouse
  document.addEventListener('mousemove', (event) => {
    if (usingLaser) {
      laserPointer.style.left = event.clientX - laserPointer.clientWidth / 2 + 'px';
      laserPointer.style.top = event.clientY - laserPointer.clientHeight / 2 + 'px';
    }
  });

  $(".gallery-item").hover(
    function() {
      $(this).css({"z-index": 999})
    },
    function() {
      $(this).css({"z-index": 0})
    }
  );

</script>

</body>

</html>
